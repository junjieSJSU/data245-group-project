{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Basic Python Libraries =====\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import io\n",
    "import pickle\n",
    "from tabulate import tabulate  \n",
    "\n",
    "# ===== Scikit-learn: Data Splitting =====\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "\n",
    "# ===== Scikit-learn: Preprocessing =====\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# ===== Scikit-learn: Classifiers =====\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# ===== Scikit-learn: Model Evaluation =====\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score, \n",
    "    classification_report, \n",
    "    confusion_matrix\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Gradient Boosting Libraries\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGBClassifier = xgb.XGBClassifier\n",
    "except ImportError:\n",
    "    print(\"Warning: XGBoost not installed. Skipping XGBoost model.\")\n",
    "    XGBClassifier = None\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    LGBMClassifier = lgb.LGBMClassifier\n",
    "except ImportError:\n",
    "    print(\"Warning: LightGBM not installed. Skipping LightGBM model.\")\n",
    "    LGBMClassifier = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET_PATH = 'Dataset/train_data.csv'\n",
    "TEST_DATASET_PATH = 'Dataset/test_data.csv'\n",
    "TARGET_COLUMN = 'Label'\n",
    "K_FOLDS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data from CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset loaded successfully from Dataset/train_data.csv\n",
      "Training dataset shape: (2558780, 85)\n",
      "\n",
      "First 5 rows of the training dataset:\n",
      "                                   FlowID       SourceIP  SourcePort  \\\n",
      "0  192.168.10.3-192.168.10.12-53-26526-17  192.168.10.12       26526   \n",
      "1   172.16.0.1-192.168.10.50-37255-3737-6     172.16.0.1       37255   \n",
      "2    192.168.10.16-72.21.91.29-53482-80-6  192.168.10.16       53482   \n",
      "3    192.168.10.15-31.13.71.7-50902-443-6     31.13.71.7         443   \n",
      "4   192.168.10.3-192.168.10.9-53-51576-17   192.168.10.9       51576   \n",
      "\n",
      "   DestinationIP  DestinationPort  Protocol            Timestamp  \\\n",
      "0   192.168.10.3               53        17        6/7/2017 3:12   \n",
      "1  192.168.10.50             3737         6        7/7/2017 2:52   \n",
      "2    72.21.91.29               80         6       5/7/2017 10:02   \n",
      "3  192.168.10.15            50902         6  03/07/2017 10:16:29   \n",
      "4   192.168.10.3               53        17        4/7/2017 4:59   \n",
      "\n",
      "   FlowDuration  TotalFwdPackets  TotalBackwardPackets  ...  \\\n",
      "0         31419                2                     2  ...   \n",
      "1            33                1                     1  ...   \n",
      "2       5713462                3                     1  ...   \n",
      "3           240                3                     1  ...   \n",
      "4           187                2                     2  ...   \n",
      "\n",
      "   min_seg_size_forward  ActiveMean  ActiveStd  ActiveMax  ActiveMin  \\\n",
      "0                    20         0.0        0.0        0.0        0.0   \n",
      "1                    24         0.0        0.0        0.0        0.0   \n",
      "2                    32         0.0        0.0        0.0        0.0   \n",
      "3                    20         0.0        0.0        0.0        0.0   \n",
      "4                    20         0.0        0.0        0.0        0.0   \n",
      "\n",
      "   IdleMean  IdleStd  IdleMax  IdleMin     Label  \n",
      "0       0.0      0.0      0.0      0.0    BENIGN  \n",
      "1       0.0      0.0      0.0      0.0  PortScan  \n",
      "2       0.0      0.0      0.0      0.0    BENIGN  \n",
      "3       0.0      0.0      0.0      0.0    BENIGN  \n",
      "4       0.0      0.0      0.0      0.0    BENIGN  \n",
      "\n",
      "[5 rows x 85 columns]\n",
      "\n",
      "Training Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2558780 entries, 0 to 2558779\n",
      "Data columns (total 85 columns):\n",
      " #   Column                   Dtype  \n",
      "---  ------                   -----  \n",
      " 0   FlowID                   object \n",
      " 1   SourceIP                 object \n",
      " 2   SourcePort               int64  \n",
      " 3   DestinationIP            object \n",
      " 4   DestinationPort          int64  \n",
      " 5   Protocol                 int64  \n",
      " 6   Timestamp                object \n",
      " 7   FlowDuration             int64  \n",
      " 8   TotalFwdPackets          int64  \n",
      " 9   TotalBackwardPackets     int64  \n",
      " 10  TotalLengthofFwdPackets  float64\n",
      " 11  TotalLengthofBwdPackets  float64\n",
      " 12  FwdPacketLengthMax       float64\n",
      " 13  FwdPacketLengthMin       float64\n",
      " 14  FwdPacketLengthMean      float64\n",
      " 15  FwdPacketLengthStd       float64\n",
      " 16  BwdPacketLengthMax       float64\n",
      " 17  BwdPacketLengthMin       float64\n",
      " 18  BwdPacketLengthMean      float64\n",
      " 19  BwdPacketLengthStd       float64\n",
      " 20  FlowBytes/s              float64\n",
      " 21  FlowPackets/s            float64\n",
      " 22  FlowIATMean              float64\n",
      " 23  FlowIATStd               float64\n",
      " 24  FlowIATMax               float64\n",
      " 25  FlowIATMin               float64\n",
      " 26  FwdIATTotal              float64\n",
      " 27  FwdIATMean               float64\n",
      " 28  FwdIATStd                float64\n",
      " 29  FwdIATMax                float64\n",
      " 30  FwdIATMin                float64\n",
      " 31  BwdIATTotal              float64\n",
      " 32  BwdIATMean               float64\n",
      " 33  BwdIATStd                float64\n",
      " 34  BwdIATMax                float64\n",
      " 35  BwdIATMin                float64\n",
      " 36  FwdPSHFlags              int64  \n",
      " 37  BwdPSHFlags              int64  \n",
      " 38  FwdURGFlags              int64  \n",
      " 39  BwdURGFlags              int64  \n",
      " 40  FwdHeaderLength          int64  \n",
      " 41  BwdHeaderLength          int64  \n",
      " 42  FwdPackets/s             float64\n",
      " 43  BwdPackets/s             float64\n",
      " 44  MinPacketLength          float64\n",
      " 45  MaxPacketLength          float64\n",
      " 46  PacketLengthMean         float64\n",
      " 47  PacketLengthStd          float64\n",
      " 48  PacketLengthVariance     float64\n",
      " 49  FINFlagCount             int64  \n",
      " 50  SYNFlagCount             int64  \n",
      " 51  RSTFlagCount             int64  \n",
      " 52  PSHFlagCount             int64  \n",
      " 53  ACKFlagCount             int64  \n",
      " 54  URGFlagCount             int64  \n",
      " 55  CWEFlagCount             int64  \n",
      " 56  ECEFlagCount             int64  \n",
      " 57  Down/UpRatio             float64\n",
      " 58  AveragePacketSize        float64\n",
      " 59  AvgFwdSegmentSize        float64\n",
      " 60  AvgBwdSegmentSize        float64\n",
      " 61  FwdHeaderLength.1        int64  \n",
      " 62  FwdAvgBytes/Bulk         int64  \n",
      " 63  FwdAvgPackets/Bulk       int64  \n",
      " 64  FwdAvgBulkRate           int64  \n",
      " 65  BwdAvgBytes/Bulk         int64  \n",
      " 66  BwdAvgPackets/Bulk       int64  \n",
      " 67  BwdAvgBulkRate           int64  \n",
      " 68  SubflowFwdPackets        int64  \n",
      " 69  SubflowFwdBytes          int64  \n",
      " 70  SubflowBwdPackets        int64  \n",
      " 71  SubflowBwdBytes          int64  \n",
      " 72  Init_Win_bytes_forward   int64  \n",
      " 73  Init_Win_bytes_backward  int64  \n",
      " 74  act_data_pkt_fwd         int64  \n",
      " 75  min_seg_size_forward     int64  \n",
      " 76  ActiveMean               float64\n",
      " 77  ActiveStd                float64\n",
      " 78  ActiveMax                float64\n",
      " 79  ActiveMin                float64\n",
      " 80  IdleMean                 float64\n",
      " 81  IdleStd                  float64\n",
      " 82  IdleMax                  float64\n",
      " 83  IdleMin                  float64\n",
      " 84  Label                    object \n",
      "dtypes: float64(45), int64(35), object(5)\n",
      "memory usage: 1.6+ GB\n",
      "\n",
      "Testing dataset loaded successfully from Dataset/test_data.csv\n",
      "Testing dataset shape: (639695, 85)\n",
      "\n",
      "First 5 rows of the testing dataset:\n",
      "                                    FlowID       SourceIP  SourcePort  \\\n",
      "0   192.168.10.5-211.233.74.132-58565-80-6   192.168.10.5       58565   \n",
      "1   192.168.10.3-192.168.10.14-53-52520-17  192.168.10.14       52520   \n",
      "2      172.16.0.1-192.168.10.50-39234-80-6     172.16.0.1       39234   \n",
      "3  192.168.10.25-104.97.133.94-55588-443-6  192.168.10.25       55588   \n",
      "4  157.240.18.35-192.168.10.15-443-54074-6  192.168.10.15       54074   \n",
      "\n",
      "    DestinationIP  DestinationPort  Protocol            Timestamp  \\\n",
      "0  211.233.74.132               80         6        6/7/2017 4:55   \n",
      "1    192.168.10.3               53        17        7/7/2017 1:57   \n",
      "2   192.168.10.50               80         6       5/7/2017 10:45   \n",
      "3   104.97.133.94              443         6  03/07/2017 10:55:48   \n",
      "4   157.240.18.35              443         6       4/7/2017 11:47   \n",
      "\n",
      "   FlowDuration  TotalFwdPackets  TotalBackwardPackets  ...  \\\n",
      "0       5658973                3                     1  ...   \n",
      "1           346                2                     2  ...   \n",
      "2             1                2                     0  ...   \n",
      "3         77778               11                     6  ...   \n",
      "4          5630                1                     1  ...   \n",
      "\n",
      "   min_seg_size_forward  ActiveMean  ActiveStd  ActiveMax  ActiveMin  \\\n",
      "0                    20         0.0        0.0        0.0        0.0   \n",
      "1                    20         0.0        0.0        0.0        0.0   \n",
      "2                    32         0.0        0.0        0.0        0.0   \n",
      "3                    32         0.0        0.0        0.0        0.0   \n",
      "4                    20         0.0        0.0        0.0        0.0   \n",
      "\n",
      "   IdleMean  IdleStd  IdleMax  IdleMin     Label  \n",
      "0       0.0      0.0      0.0      0.0    BENIGN  \n",
      "1       0.0      0.0      0.0      0.0    BENIGN  \n",
      "2       0.0      0.0      0.0      0.0  DoS Hulk  \n",
      "3       0.0      0.0      0.0      0.0    BENIGN  \n",
      "4       0.0      0.0      0.0      0.0    BENIGN  \n",
      "\n",
      "[5 rows x 85 columns]\n",
      "\n",
      "Testing Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 639695 entries, 0 to 639694\n",
      "Data columns (total 85 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   FlowID                   639695 non-null  object \n",
      " 1   SourceIP                 639695 non-null  object \n",
      " 2   SourcePort               639695 non-null  int64  \n",
      " 3   DestinationIP            639695 non-null  object \n",
      " 4   DestinationPort          639695 non-null  int64  \n",
      " 5   Protocol                 639695 non-null  int64  \n",
      " 6   Timestamp                639695 non-null  object \n",
      " 7   FlowDuration             639695 non-null  int64  \n",
      " 8   TotalFwdPackets          639695 non-null  int64  \n",
      " 9   TotalBackwardPackets     639695 non-null  int64  \n",
      " 10  TotalLengthofFwdPackets  639695 non-null  float64\n",
      " 11  TotalLengthofBwdPackets  639695 non-null  float64\n",
      " 12  FwdPacketLengthMax       639695 non-null  float64\n",
      " 13  FwdPacketLengthMin       639695 non-null  float64\n",
      " 14  FwdPacketLengthMean      639695 non-null  float64\n",
      " 15  FwdPacketLengthStd       639695 non-null  float64\n",
      " 16  BwdPacketLengthMax       639695 non-null  float64\n",
      " 17  BwdPacketLengthMin       639695 non-null  float64\n",
      " 18  BwdPacketLengthMean      639695 non-null  float64\n",
      " 19  BwdPacketLengthStd       639695 non-null  float64\n",
      " 20  FlowBytes/s              639695 non-null  float64\n",
      " 21  FlowPackets/s            639695 non-null  float64\n",
      " 22  FlowIATMean              639695 non-null  float64\n",
      " 23  FlowIATStd               639695 non-null  float64\n",
      " 24  FlowIATMax               639695 non-null  float64\n",
      " 25  FlowIATMin               639695 non-null  float64\n",
      " 26  FwdIATTotal              639695 non-null  float64\n",
      " 27  FwdIATMean               639695 non-null  float64\n",
      " 28  FwdIATStd                639695 non-null  float64\n",
      " 29  FwdIATMax                639695 non-null  float64\n",
      " 30  FwdIATMin                639695 non-null  float64\n",
      " 31  BwdIATTotal              639695 non-null  float64\n",
      " 32  BwdIATMean               639695 non-null  float64\n",
      " 33  BwdIATStd                639695 non-null  float64\n",
      " 34  BwdIATMax                639695 non-null  float64\n",
      " 35  BwdIATMin                639695 non-null  float64\n",
      " 36  FwdPSHFlags              639695 non-null  int64  \n",
      " 37  BwdPSHFlags              639695 non-null  int64  \n",
      " 38  FwdURGFlags              639695 non-null  int64  \n",
      " 39  BwdURGFlags              639695 non-null  int64  \n",
      " 40  FwdHeaderLength          639695 non-null  int64  \n",
      " 41  BwdHeaderLength          639695 non-null  int64  \n",
      " 42  FwdPackets/s             639695 non-null  float64\n",
      " 43  BwdPackets/s             639695 non-null  float64\n",
      " 44  MinPacketLength          639695 non-null  float64\n",
      " 45  MaxPacketLength          639695 non-null  float64\n",
      " 46  PacketLengthMean         639695 non-null  float64\n",
      " 47  PacketLengthStd          639695 non-null  float64\n",
      " 48  PacketLengthVariance     639695 non-null  float64\n",
      " 49  FINFlagCount             639695 non-null  int64  \n",
      " 50  SYNFlagCount             639695 non-null  int64  \n",
      " 51  RSTFlagCount             639695 non-null  int64  \n",
      " 52  PSHFlagCount             639695 non-null  int64  \n",
      " 53  ACKFlagCount             639695 non-null  int64  \n",
      " 54  URGFlagCount             639695 non-null  int64  \n",
      " 55  CWEFlagCount             639695 non-null  int64  \n",
      " 56  ECEFlagCount             639695 non-null  int64  \n",
      " 57  Down/UpRatio             639695 non-null  float64\n",
      " 58  AveragePacketSize        639695 non-null  float64\n",
      " 59  AvgFwdSegmentSize        639695 non-null  float64\n",
      " 60  AvgBwdSegmentSize        639695 non-null  float64\n",
      " 61  FwdHeaderLength.1        639695 non-null  int64  \n",
      " 62  FwdAvgBytes/Bulk         639695 non-null  int64  \n",
      " 63  FwdAvgPackets/Bulk       639695 non-null  int64  \n",
      " 64  FwdAvgBulkRate           639695 non-null  int64  \n",
      " 65  BwdAvgBytes/Bulk         639695 non-null  int64  \n",
      " 66  BwdAvgPackets/Bulk       639695 non-null  int64  \n",
      " 67  BwdAvgBulkRate           639695 non-null  int64  \n",
      " 68  SubflowFwdPackets        639695 non-null  int64  \n",
      " 69  SubflowFwdBytes          639695 non-null  int64  \n",
      " 70  SubflowBwdPackets        639695 non-null  int64  \n",
      " 71  SubflowBwdBytes          639695 non-null  int64  \n",
      " 72  Init_Win_bytes_forward   639695 non-null  int64  \n",
      " 73  Init_Win_bytes_backward  639695 non-null  int64  \n",
      " 74  act_data_pkt_fwd         639695 non-null  int64  \n",
      " 75  min_seg_size_forward     639695 non-null  int64  \n",
      " 76  ActiveMean               639695 non-null  float64\n",
      " 77  ActiveStd                639695 non-null  float64\n",
      " 78  ActiveMax                639695 non-null  float64\n",
      " 79  ActiveMin                639695 non-null  float64\n",
      " 80  IdleMean                 639695 non-null  float64\n",
      " 81  IdleStd                  639695 non-null  float64\n",
      " 82  IdleMax                  639695 non-null  float64\n",
      " 83  IdleMin                  639695 non-null  float64\n",
      " 84  Label                    639695 non-null  object \n",
      "dtypes: float64(45), int64(35), object(5)\n",
      "memory usage: 414.8+ MB\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_train = pd.read_csv(TRAIN_DATASET_PATH)\n",
    "    print(f\"Training dataset loaded successfully from {TRAIN_DATASET_PATH}\")\n",
    "    print(f\"Training dataset shape: {df_train.shape}\")\n",
    "    print(\"\\nFirst 5 rows of the training dataset:\")\n",
    "    print(df_train.head())\n",
    "    print(\"\\nTraining Dataset Info:\")\n",
    "    df_train.info()\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Training dataset not found at {TRAIN_DATASET_PATH}\")\n",
    "    print(\"Please update TRAIN_DATASET_PATH with the correct path to your training CSV file.\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    df_test = pd.read_csv(TEST_DATASET_PATH)\n",
    "    print(f\"\\nTesting dataset loaded successfully from {TEST_DATASET_PATH}\")\n",
    "    print(f\"Testing dataset shape: {df_test.shape}\")\n",
    "    print(\"\\nFirst 5 rows of the testing dataset:\")\n",
    "    print(df_test.head())\n",
    "    print(\"\\nTesting Dataset Info:\")\n",
    "    df_test.info()\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Testing dataset not found at {TEST_DATASET_PATH}\")\n",
    "    print(\"Please update TEST_DATASET_PATH with the correct path to your testing CSV file.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Training Labels: ['ATTACK' 'BENIGN']\n",
      "Encoded Training Labels: ['ATTACK' 'BENIGN']\n",
      "\n",
      "Original Testing Labels: ['BENIGN' 'ATTACK']\n",
      "Encoded Testing Labels (based on training labels): ['ATTACK' 'BENIGN']\n",
      "\n",
      "Label encoder saved to label_encoder.pkl\n",
      "\n",
      "Features scaled using StandardScaler (fitted on training data).\n",
      "Standard scaler saved to scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = ['FlowID', 'SourceIP', 'DestinationIP', 'Timestamp']\n",
    "\n",
    "# Apply dropping columns and handling infinite/NaN values to both dataframes\n",
    "def preprocess_dataframe(df, columns_to_drop, target_column, desired_sample_size):\n",
    "    df_processed = df.drop(columns=columns_to_drop, errors='ignore').copy()\n",
    "    # Handle potential infinite values\n",
    "    df_processed.replace([float('inf'), float('-inf')], pd.NA, inplace=True)\n",
    "    # Fill NaN values. Using 0 here, but consider other strategies.\n",
    "    df_processed.fillna(0, inplace=True)\n",
    "\n",
    "    if isinstance(desired_sample_size, str) and desired_sample_size.lower() == 'all':\n",
    "        df_sampled = df_processed\n",
    "    else:\n",
    "        sample_frac = desired_sample_size / len(df_processed)\n",
    "        df_sampled, _ = train_test_split(\n",
    "            df_processed,\n",
    "            test_size=1 - sample_frac,\n",
    "            stratify=df_processed[target_column],\n",
    "            random_state=42\n",
    "        )\n",
    "    \n",
    "    # Separate features (X) and target (y)\n",
    "    X = df_sampled.drop(columns=[target_column])\n",
    "    y = df_sampled[target_column]\n",
    "\n",
    "    y = y.astype(str)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = preprocess_dataframe(df_train, columns_to_drop, TARGET_COLUMN, 'all')\n",
    "X_test, y_test = preprocess_dataframe(df_test, columns_to_drop, TARGET_COLUMN, 'all')\n",
    "\n",
    "\n",
    "def simplify_labels(y):\n",
    "    return y.apply(lambda x: 'BENIGN' if x.upper() == 'BENIGN' else 'ATTACK')\n",
    "\n",
    "y_train = simplify_labels(y_train)\n",
    "y_test = simplify_labels(y_test)\n",
    "\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "print(f\"\\nOriginal Training Labels: {y_train.unique()}\")\n",
    "print(f\"Encoded Training Labels: {label_encoder.classes_}\")\n",
    "print(f\"\\nOriginal Testing Labels: {y_test.unique()}\")\n",
    "print(f\"Encoded Testing Labels (based on training labels): {label_encoder.classes_}\")\n",
    "\n",
    "# --- Save the LabelEncoder ---\n",
    "try:\n",
    "    encoder_filename = 'label_encoder.pkl'\n",
    "    with open(encoder_filename, 'wb') as f:\n",
    "        pickle.dump(label_encoder, f)\n",
    "    print(f\"\\nLabel encoder saved to {encoder_filename}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving label encoder: {e}\")\n",
    "\n",
    "# Scale numerical features\n",
    "# Fit scaler ONLY on training data, then transform both train and test data\n",
    "scaler = StandardScaler()\n",
    "# Check if training data is not empty before scaling\n",
    "if X_train.shape[0] > 0:\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    print(f\"\\nFeatures scaled using StandardScaler (fitted on training data).\")\n",
    "\n",
    "    # --- Save the StandardScaler ---\n",
    "    try:\n",
    "        scaler_filename = 'scaler.pkl'\n",
    "        with open(scaler_filename, 'wb') as f:\n",
    "            pickle.dump(scaler, f)\n",
    "        print(f\"Standard scaler saved to {scaler_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving standard scaler: {e}\")\n",
    "else:\n",
    "    print(\"\\nWarning: Training data is empty after preprocessing. Cannot scale features or train models.\")\n",
    "    X_train_scaled = X_train\n",
    "    X_test_scaled = X_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining models to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"SGD Classifier\": SGDClassifier(loss='log_loss', max_iter=1000, tol=1e-3, random_state=42),\n",
    "    \"MLP Classifier\": MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42),\n",
    "    \"Bagging Classifier (Decision Tree)\": BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Add Gradient Boosting models if installed\n",
    "if XGBClassifier is not None:\n",
    "    models[\"XGBoost\"] = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "if LGBMClassifier is not None:\n",
    "    models[\"LightGBM\"] = LGBMClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation to evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting K-Fold Cross-Validation (K=5) ---\n",
      "\n",
      "Performing 5-fold cross-validation for Logistic Regression...\n",
      "  Fold 1/5 - Accuracy: 0.9283, Precision: 0.9316, Recall: 0.9283, F1: 0.9295, Time: 0.06s\n",
      "  Fold 2/5 - Accuracy: 0.9483, Precision: 0.9477, Recall: 0.9483, F1: 0.9476, Time: 0.04s\n",
      "  Fold 3/5 - Accuracy: 0.9350, Precision: 0.9342, Recall: 0.9350, F1: 0.9343, Time: 0.04s\n",
      "  Fold 4/5 - Accuracy: 0.9300, Precision: 0.9303, Recall: 0.9300, F1: 0.9302, Time: 0.04s\n",
      "  Fold 5/5 - Accuracy: 0.9100, Precision: 0.9146, Recall: 0.9100, F1: 0.9117, Time: 0.04s\n",
      "\n",
      "Logistic Regression - Average CV Metrics:\n",
      "  Accuracy: 0.9303 (±0.0124)\n",
      "  Precision: 0.9317 (±0.0106)\n",
      "  Recall: 0.9303 (±0.0124)\n",
      "  F1-Score: 0.9307 (±0.0115)\n",
      "  Avg Training Time: 0.0457s\n",
      "\n",
      "Performing 5-fold cross-validation for Decision Tree...\n",
      "  Fold 1/5 - Accuracy: 0.9867, Precision: 0.9870, Recall: 0.9867, F1: 0.9868, Time: 0.06s\n",
      "  Fold 2/5 - Accuracy: 0.9983, Precision: 0.9983, Recall: 0.9983, F1: 0.9983, Time: 0.08s\n",
      "  Fold 3/5 - Accuracy: 0.9883, Precision: 0.9883, Recall: 0.9883, F1: 0.9883, Time: 0.08s\n",
      "  Fold 4/5 - Accuracy: 0.9883, Precision: 0.9883, Recall: 0.9883, F1: 0.9883, Time: 0.07s\n",
      "  Fold 5/5 - Accuracy: 0.9883, Precision: 0.9883, Recall: 0.9883, F1: 0.9883, Time: 0.05s\n",
      "\n",
      "Decision Tree - Average CV Metrics:\n",
      "  Accuracy: 0.9900 (±0.0042)\n",
      "  Precision: 0.9900 (±0.0042)\n",
      "  Recall: 0.9900 (±0.0042)\n",
      "  F1-Score: 0.9900 (±0.0042)\n",
      "  Avg Training Time: 0.0699s\n",
      "\n",
      "Performing 5-fold cross-validation for Random Forest...\n",
      "  Fold 1/5 - Accuracy: 0.9917, Precision: 0.9917, Recall: 0.9917, F1: 0.9917, Time: 0.52s\n",
      "  Fold 2/5 - Accuracy: 0.9967, Precision: 0.9967, Recall: 0.9967, F1: 0.9967, Time: 0.57s\n",
      "  Fold 3/5 - Accuracy: 0.9933, Precision: 0.9933, Recall: 0.9933, F1: 0.9933, Time: 0.58s\n",
      "  Fold 4/5 - Accuracy: 0.9917, Precision: 0.9917, Recall: 0.9917, F1: 0.9916, Time: 0.52s\n",
      "  Fold 5/5 - Accuracy: 0.9883, Precision: 0.9883, Recall: 0.9883, F1: 0.9883, Time: 0.50s\n",
      "\n",
      "Random Forest - Average CV Metrics:\n",
      "  Accuracy: 0.9923 (±0.0027)\n",
      "  Precision: 0.9923 (±0.0027)\n",
      "  Recall: 0.9923 (±0.0027)\n",
      "  F1-Score: 0.9923 (±0.0027)\n",
      "  Avg Training Time: 0.5383s\n",
      "\n",
      "Performing 5-fold cross-validation for K-Nearest Neighbors...\n",
      "  Fold 1/5 - Accuracy: 0.9617, Precision: 0.9634, Recall: 0.9617, F1: 0.9622, Time: 0.00s\n",
      "  Fold 2/5 - Accuracy: 0.9667, Precision: 0.9665, Recall: 0.9667, F1: 0.9666, Time: 0.00s\n",
      "  Fold 3/5 - Accuracy: 0.9667, Precision: 0.9674, Recall: 0.9667, F1: 0.9669, Time: 0.00s\n",
      "  Fold 4/5 - Accuracy: 0.9567, Precision: 0.9575, Recall: 0.9567, F1: 0.9570, Time: 0.00s\n",
      "  Fold 5/5 - Accuracy: 0.9433, Precision: 0.9474, Recall: 0.9433, F1: 0.9445, Time: 0.00s\n",
      "\n",
      "K-Nearest Neighbors - Average CV Metrics:\n",
      "  Accuracy: 0.9590 (±0.0087)\n",
      "  Precision: 0.9604 (±0.0074)\n",
      "  Recall: 0.9590 (±0.0087)\n",
      "  F1-Score: 0.9594 (±0.0083)\n",
      "  Avg Training Time: 0.0004s\n",
      "\n",
      "Performing 5-fold cross-validation for Gaussian Naive Bayes...\n",
      "  Fold 1/5 - Accuracy: 0.7433, Precision: 0.8872, Recall: 0.7433, F1: 0.7702, Time: 0.00s\n",
      "  Fold 2/5 - Accuracy: 0.7750, Precision: 0.8672, Recall: 0.7750, F1: 0.7916, Time: 0.00s\n",
      "  Fold 3/5 - Accuracy: 0.7267, Precision: 0.8625, Recall: 0.7267, F1: 0.7453, Time: 0.00s\n",
      "  Fold 4/5 - Accuracy: 0.7450, Precision: 0.8725, Recall: 0.7450, F1: 0.7628, Time: 0.00s\n",
      "  Fold 5/5 - Accuracy: 0.7083, Precision: 0.8660, Recall: 0.7083, F1: 0.7346, Time: 0.00s\n",
      "\n",
      "Gaussian Naive Bayes - Average CV Metrics:\n",
      "  Accuracy: 0.7397 (±0.0221)\n",
      "  Precision: 0.8711 (±0.0087)\n",
      "  Recall: 0.7397 (±0.0221)\n",
      "  F1-Score: 0.7609 (±0.0199)\n",
      "  Avg Training Time: 0.0011s\n",
      "\n",
      "Performing 5-fold cross-validation for SGD Classifier...\n",
      "  Fold 1/5 - Accuracy: 0.9183, Precision: 0.9161, Recall: 0.9183, F1: 0.9168, Time: 0.03s\n",
      "  Fold 2/5 - Accuracy: 0.9383, Precision: 0.9374, Recall: 0.9383, F1: 0.9374, Time: 0.02s\n",
      "  Fold 3/5 - Accuracy: 0.9467, Precision: 0.9467, Recall: 0.9467, F1: 0.9467, Time: 0.01s\n",
      "  Fold 4/5 - Accuracy: 0.9217, Precision: 0.9203, Recall: 0.9217, F1: 0.9200, Time: 0.03s\n",
      "  Fold 5/5 - Accuracy: 0.8933, Precision: 0.8940, Recall: 0.8933, F1: 0.8936, Time: 0.02s\n",
      "\n",
      "SGD Classifier - Average CV Metrics:\n",
      "  Accuracy: 0.9237 (±0.0184)\n",
      "  Precision: 0.9229 (±0.0183)\n",
      "  Recall: 0.9237 (±0.0184)\n",
      "  F1-Score: 0.9229 (±0.0183)\n",
      "  Avg Training Time: 0.0212s\n",
      "\n",
      "Performing 5-fold cross-validation for MLP Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeffc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1/5 - Accuracy: 0.9850, Precision: 0.9849, Recall: 0.9850, F1: 0.9849, Time: 5.16s\n",
      "  Fold 2/5 - Accuracy: 0.9750, Precision: 0.9749, Recall: 0.9750, F1: 0.9749, Time: 4.65s\n",
      "  Fold 3/5 - Accuracy: 0.9750, Precision: 0.9751, Recall: 0.9750, F1: 0.9750, Time: 5.07s\n",
      "  Fold 4/5 - Accuracy: 0.9817, Precision: 0.9816, Recall: 0.9817, F1: 0.9816, Time: 5.09s\n",
      "  Fold 5/5 - Accuracy: 0.9817, Precision: 0.9817, Recall: 0.9817, F1: 0.9817, Time: 4.93s\n",
      "\n",
      "MLP Classifier - Average CV Metrics:\n",
      "  Accuracy: 0.9797 (±0.0040)\n",
      "  Precision: 0.9796 (±0.0040)\n",
      "  Recall: 0.9797 (±0.0040)\n",
      "  F1-Score: 0.9796 (±0.0040)\n",
      "  Avg Training Time: 4.9807s\n",
      "\n",
      "Performing 5-fold cross-validation for Bagging Classifier (Decision Tree)...\n",
      "  Fold 1/5 - Accuracy: 0.9900, Precision: 0.9901, Recall: 0.9900, F1: 0.9900, Time: 4.27s\n",
      "  Fold 2/5 - Accuracy: 0.9950, Precision: 0.9950, Recall: 0.9950, F1: 0.9950, Time: 4.97s\n",
      "  Fold 3/5 - Accuracy: 0.9917, Precision: 0.9917, Recall: 0.9917, F1: 0.9917, Time: 4.99s\n",
      "  Fold 4/5 - Accuracy: 0.9967, Precision: 0.9967, Recall: 0.9967, F1: 0.9967, Time: 4.70s\n",
      "  Fold 5/5 - Accuracy: 0.9867, Precision: 0.9866, Recall: 0.9867, F1: 0.9866, Time: 3.70s\n",
      "\n",
      "Bagging Classifier (Decision Tree) - Average CV Metrics:\n",
      "  Accuracy: 0.9920 (±0.0036)\n",
      "  Precision: 0.9920 (±0.0036)\n",
      "  Recall: 0.9920 (±0.0036)\n",
      "  F1-Score: 0.9920 (±0.0036)\n",
      "  Avg Training Time: 4.5240s\n",
      "\n",
      "Performing 5-fold cross-validation for XGBoost...\n",
      "  Fold 1/5 - Accuracy: 0.9933, Precision: 0.9934, Recall: 0.9933, F1: 0.9934, Time: 0.08s\n",
      "  Fold 2/5 - Accuracy: 0.9983, Precision: 0.9983, Recall: 0.9983, F1: 0.9983, Time: 0.08s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeffc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [15:01:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\jeffc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [15:01:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\jeffc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [15:01:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 3/5 - Accuracy: 0.9950, Precision: 0.9950, Recall: 0.9950, F1: 0.9950, Time: 0.09s\n",
      "  Fold 4/5 - Accuracy: 0.9950, Precision: 0.9950, Recall: 0.9950, F1: 0.9950, Time: 0.09s\n",
      "  Fold 5/5 - Accuracy: 0.9917, Precision: 0.9917, Recall: 0.9917, F1: 0.9916, Time: 0.08s\n",
      "\n",
      "XGBoost - Average CV Metrics:\n",
      "  Accuracy: 0.9947 (±0.0022)\n",
      "  Precision: 0.9947 (±0.0022)\n",
      "  Recall: 0.9947 (±0.0022)\n",
      "  F1-Score: 0.9947 (±0.0022)\n",
      "  Avg Training Time: 0.0828s\n",
      "\n",
      "Performing 5-fold cross-validation for LightGBM...\n",
      "[LightGBM] [Info] Number of positive: 1836, number of negative: 564\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11538\n",
      "[LightGBM] [Info] Number of data points in the train set: 2400, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.765000 -> initscore=1.180290\n",
      "[LightGBM] [Info] Start training from score 1.180290\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeffc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [15:01:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\jeffc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [15:01:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1/5 - Accuracy: 0.9933, Precision: 0.9934, Recall: 0.9933, F1: 0.9934, Time: 0.11s\n",
      "[LightGBM] [Info] Number of positive: 1861, number of negative: 539\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11536\n",
      "[LightGBM] [Info] Number of data points in the train set: 2400, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.775417 -> initscore=1.239154\n",
      "[LightGBM] [Info] Start training from score 1.239154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "  Fold 2/5 - Accuracy: 0.9983, Precision: 0.9983, Recall: 0.9983, F1: 0.9983, Time: 0.11s\n",
      "[LightGBM] [Info] Number of positive: 1868, number of negative: 532\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001084 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11550\n",
      "[LightGBM] [Info] Number of data points in the train set: 2400, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.778333 -> initscore=1.255980\n",
      "[LightGBM] [Info] Start training from score 1.255980\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "  Fold 3/5 - Accuracy: 0.9950, Precision: 0.9950, Recall: 0.9950, F1: 0.9950, Time: 0.11s\n",
      "[LightGBM] [Info] Number of positive: 1867, number of negative: 533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001006 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11600\n",
      "[LightGBM] [Info] Number of data points in the train set: 2400, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.777917 -> initscore=1.253567\n",
      "[LightGBM] [Info] Start training from score 1.253567\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "  Fold 4/5 - Accuracy: 0.9917, Precision: 0.9917, Recall: 0.9917, F1: 0.9917, Time: 0.10s\n",
      "[LightGBM] [Info] Number of positive: 1848, number of negative: 552\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11594\n",
      "[LightGBM] [Info] Number of data points in the train set: 2400, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.770000 -> initscore=1.208311\n",
      "[LightGBM] [Info] Start training from score 1.208311\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "  Fold 5/5 - Accuracy: 0.9933, Precision: 0.9933, Recall: 0.9933, F1: 0.9933, Time: 0.11s\n",
      "\n",
      "LightGBM - Average CV Metrics:\n",
      "  Accuracy: 0.9943 (±0.0023)\n",
      "  Precision: 0.9943 (±0.0023)\n",
      "  Recall: 0.9943 (±0.0023)\n",
      "  F1-Score: 0.9943 (±0.0023)\n",
      "  Avg Training Time: 0.1083s\n"
     ]
    }
   ],
   "source": [
    "cv_results = {}\n",
    "\n",
    "print(\"\\n--- Starting K-Fold Cross-Validation (K={}) ---\".format(K_FOLDS))\n",
    "\n",
    "# Perform k-fold cross-validation for each model\n",
    "if X_train_scaled.shape[0] > 0 and len(label_encoder.classes_) > 0:\n",
    "    kf = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nPerforming {K_FOLDS}-fold cross-validation for {name}...\")\n",
    "        fold_accuracies = []\n",
    "        fold_precisions = []\n",
    "        fold_recalls = []\n",
    "        fold_f1_scores = []\n",
    "        fold_times = []\n",
    "        \n",
    "        # Perform K-fold CV manually to get more metrics than just accuracy\n",
    "        fold_num = 1\n",
    "        \n",
    "        for train_index, val_index in kf.split(X_train_scaled):\n",
    "            X_fold_train, X_fold_val = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "            y_fold_train, y_fold_val = y_train_encoded[train_index], y_train_encoded[val_index]\n",
    "            \n",
    "            # Train the model\n",
    "            start_time = time.time()\n",
    "            try:\n",
    "                model.fit(X_fold_train, y_fold_train)\n",
    "                train_time = time.time() - start_time\n",
    "                \n",
    "                # Predict and evaluate\n",
    "                y_fold_pred = model.predict(X_fold_val)\n",
    "                \n",
    "                # Calculate metrics\n",
    "                accuracy = accuracy_score(y_fold_val, y_fold_pred)\n",
    "                precision = precision_score(y_fold_val, y_fold_pred, average='weighted', zero_division=0)\n",
    "                recall = recall_score(y_fold_val, y_fold_pred, average='weighted', zero_division=0)\n",
    "                f1 = f1_score(y_fold_val, y_fold_pred, average='weighted', zero_division=0)\n",
    "                \n",
    "                # Store metrics\n",
    "                fold_accuracies.append(accuracy)\n",
    "                fold_precisions.append(precision)\n",
    "                fold_recalls.append(recall)\n",
    "                fold_f1_scores.append(f1)\n",
    "                fold_times.append(train_time)\n",
    "                \n",
    "                print(f\"  Fold {fold_num}/{K_FOLDS} - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, \"\n",
    "                      f\"Recall: {recall:.4f}, F1: {f1:.4f}, Time: {train_time:.2f}s\")\n",
    "                \n",
    "                fold_num += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  Error in fold {fold_num} for {name}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Calculate average metrics across folds\n",
    "        if fold_accuracies:\n",
    "            avg_accuracy = np.mean(fold_accuracies)\n",
    "            avg_precision = np.mean(fold_precisions)\n",
    "            avg_recall = np.mean(fold_recalls)\n",
    "            avg_f1 = np.mean(fold_f1_scores)\n",
    "            avg_time = np.mean(fold_times)\n",
    "            \n",
    "            cv_results[name] = {\n",
    "                \"Accuracy\": avg_accuracy,\n",
    "                \"Precision\": avg_precision,\n",
    "                \"Recall\": avg_recall,\n",
    "                \"F1-Score\": avg_f1,\n",
    "                \"Training Time\": avg_time\n",
    "            }\n",
    "            \n",
    "            print(f\"\\n{name} - Average CV Metrics:\")\n",
    "            print(f\"  Accuracy: {avg_accuracy:.4f} (±{np.std(fold_accuracies):.4f})\")\n",
    "            print(f\"  Precision: {avg_precision:.4f} (±{np.std(fold_precisions):.4f})\")\n",
    "            print(f\"  Recall: {avg_recall:.4f} (±{np.std(fold_recalls):.4f})\")\n",
    "            print(f\"  F1-Score: {avg_f1:.4f} (±{np.std(fold_f1_scores):.4f})\")\n",
    "            print(f\"  Avg Training Time: {avg_time:.4f}s\")\n",
    "        else:\n",
    "            cv_results[name] = {\"Error\": \"Failed to complete cross-validation\"}\n",
    "else:\n",
    "    print(\"\\nSkipping cross-validation due to insufficient data or classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cross-Validation Summary ---\n",
      "+------------------------------------+------------+-------------+----------+------------+---------------------+\n",
      "| Model                              |   Accuracy |   Precision |   Recall |   F1-Score |   Training Time (s) |\n",
      "+====================================+============+=============+==========+============+=====================+\n",
      "| Logistic Regression                |     0.9303 |      0.9317 |   0.9303 |     0.9307 |              0.0457 |\n",
      "+------------------------------------+------------+-------------+----------+------------+---------------------+\n",
      "| Decision Tree                      |     0.99   |      0.99   |   0.99   |     0.99   |              0.0699 |\n",
      "+------------------------------------+------------+-------------+----------+------------+---------------------+\n",
      "| Random Forest                      |     0.9923 |      0.9923 |   0.9923 |     0.9923 |              0.5383 |\n",
      "+------------------------------------+------------+-------------+----------+------------+---------------------+\n",
      "| K-Nearest Neighbors                |     0.959  |      0.9604 |   0.959  |     0.9594 |              0.0004 |\n",
      "+------------------------------------+------------+-------------+----------+------------+---------------------+\n",
      "| Gaussian Naive Bayes               |     0.7397 |      0.8711 |   0.7397 |     0.7609 |              0.0011 |\n",
      "+------------------------------------+------------+-------------+----------+------------+---------------------+\n",
      "| SGD Classifier                     |     0.9237 |      0.9229 |   0.9237 |     0.9229 |              0.0212 |\n",
      "+------------------------------------+------------+-------------+----------+------------+---------------------+\n",
      "| MLP Classifier                     |     0.9797 |      0.9796 |   0.9797 |     0.9796 |              4.9807 |\n",
      "+------------------------------------+------------+-------------+----------+------------+---------------------+\n",
      "| Bagging Classifier (Decision Tree) |     0.992  |      0.992  |   0.992  |     0.992  |              4.524  |\n",
      "+------------------------------------+------------+-------------+----------+------------+---------------------+\n",
      "| XGBoost                            |     0.9947 |      0.9947 |   0.9947 |     0.9947 |              0.0828 |\n",
      "+------------------------------------+------------+-------------+----------+------------+---------------------+\n",
      "| LightGBM                           |     0.9943 |      0.9943 |   0.9943 |     0.9943 |              0.1083 |\n",
      "+------------------------------------+------------+-------------+----------+------------+---------------------+\n",
      "\n",
      "--- Best Model Based on F1-Score ---\n",
      "Selected Model: XGBoost\n",
      "CV F1-Score: 0.9947\n",
      "\n",
      "--- Training XGBoost on Full Training Dataset ---\n",
      "Training completed in 0.0884 seconds\n",
      "Best model saved to best_model_XGBoost.pkl\n",
      "\n",
      "--- Evaluating XGBoost on Test Dataset ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeffc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [15:02:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Test Results for XGBoost ---\n",
      "Accuracy: 0.9956\n",
      "Precision: 0.9957\n",
      "Recall: 0.9956\n",
      "F1-Score: 0.9956\n",
      "Prediction Time: 0.1518 seconds\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ATTACK       0.99      0.99      0.99    145426\n",
      "      BENIGN       1.00      1.00      1.00    494269\n",
      "\n",
      "    accuracy                           1.00    639695\n",
      "   macro avg       0.99      1.00      0.99    639695\n",
      "weighted avg       1.00      1.00      1.00    639695\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[144677    749]\n",
      " [  2042 492227]]\n",
      "\n",
      "--- CV vs Test Performance Comparison ---\n",
      "CV F1-Score: 0.9947\n",
      "Test F1-Score: 0.9956\n",
      "Difference: 0.0010\n"
     ]
    }
   ],
   "source": [
    "if cv_results:\n",
    "    # Create a summary table\n",
    "    summary_data = []\n",
    "    headers = [\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"Training Time (s)\"]\n",
    "    \n",
    "    for name, metrics in cv_results.items():\n",
    "        if \"Error\" not in metrics:\n",
    "            row = [\n",
    "                name, \n",
    "                f\"{metrics['Accuracy']:.4f}\", \n",
    "                f\"{metrics['Precision']:.4f}\", \n",
    "                f\"{metrics['Recall']:.4f}\", \n",
    "                f\"{metrics['F1-Score']:.4f}\",\n",
    "                f\"{metrics['Training Time']:.4f}\"\n",
    "            ]\n",
    "            summary_data.append(row)\n",
    "    \n",
    "    # Display summary table\n",
    "    print(\"\\n--- Cross-Validation Summary ---\")\n",
    "    print(tabulate(summary_data, headers=headers, tablefmt=\"grid\"))\n",
    "    \n",
    "    # Select the best model based on F1-Score (you can change this to another metric if preferred)\n",
    "    best_model_name = max(cv_results.items(), key=lambda x: x[1]['F1-Score'] if \"Error\" not in x[1] else -1)[0]\n",
    "    best_model = models[best_model_name]\n",
    "    best_cv_f1 = cv_results[best_model_name]['F1-Score']\n",
    "    \n",
    "    print(f\"\\n--- Best Model Based on F1-Score ---\")\n",
    "    print(f\"Selected Model: {best_model_name}\")\n",
    "    print(f\"CV F1-Score: {best_cv_f1:.4f}\")\n",
    "    \n",
    "    # --- 5. Train Best Model on Full Training Dataset ---\n",
    "    print(f\"\\n--- Training {best_model_name} on Full Training Dataset ---\")\n",
    "    start_time = time.time()\n",
    "    best_model.fit(X_train_scaled, y_train_encoded)\n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"Training completed in {training_time:.4f} seconds\")\n",
    "    \n",
    "    # Save the best model\n",
    "    try:\n",
    "        best_model_filename = f\"best_model_{best_model_name.replace(' ', '_').replace('(', '').replace(')', '')}.pkl\"\n",
    "        with open(best_model_filename, 'wb') as f:\n",
    "            pickle.dump(best_model, f)\n",
    "        print(f\"Best model saved to {best_model_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving best model: {e}\")\n",
    "    \n",
    "    # --- 6. Evaluate Best Model on Test Dataset ---\n",
    "    print(f\"\\n--- Evaluating {best_model_name} on Test Dataset ---\")\n",
    "    start_time = time.time()\n",
    "    y_pred_encoded = best_model.predict(X_test_scaled)\n",
    "    prediction_time = time.time() - start_time\n",
    "    \n",
    "    # Convert encoded predictions back to original labels\n",
    "    y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "    y_test_original = label_encoder.inverse_transform(y_test_encoded)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_encoded, y_pred_encoded)\n",
    "    precision = precision_score(y_test_encoded, y_pred_encoded, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test_encoded, y_pred_encoded, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test_encoded, y_pred_encoded, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"\\n--- Final Test Results for {best_model_name} ---\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"Prediction Time: {prediction_time:.4f} seconds\")\n",
    "    \n",
    "    # Display classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test_encoded, y_pred_encoded, target_names=label_encoder.classes_, zero_division=0))\n",
    "    \n",
    "    # Display confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test_encoded, y_pred_encoded)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    \n",
    "    # Compare CV performance with test performance\n",
    "    print(\"\\n--- CV vs Test Performance Comparison ---\")\n",
    "    print(f\"CV F1-Score: {best_cv_f1:.4f}\")\n",
    "    print(f\"Test F1-Score: {f1:.4f}\")\n",
    "    print(f\"Difference: {f1 - best_cv_f1:.4f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nNo valid cross-validation results. Cannot select best model.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
