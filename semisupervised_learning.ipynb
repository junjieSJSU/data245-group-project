{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8mPavHKons-h"
      },
      "outputs": [],
      "source": [
        "# ===== Basic Python Libraries =====\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import joblib\n",
        "import pickle\n",
        "\n",
        "# ===== Scikit-learn: Semi-Supervised Models =====\n",
        "from sklearn.semi_supervised import LabelPropagation, LabelSpreading, SelfTrainingClassifier\n",
        "\n",
        "# ===== Scikit-learn: Base Classifiers =====\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# ===== Scikit-learn: Preprocessing =====\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# ===== Scikit-learn: Data Splitting =====\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold, train_test_split\n",
        "\n",
        "# ===== Scikit-learn: Model Evaluation =====\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    balanced_accuracy_score,\n",
        "    classification_report,\n",
        "    confusion_matrix\n",
        ")\n",
        "\n",
        "# ===== Scikit-learn: Utilities =====\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.base import clone\n",
        "\n",
        "# ===== Visualization Libraries =====\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# ===== Scikit-learn: Hyperparameter Tuning =====\n",
        "from sklearn.model_selection import GridSearchCV, ParameterGrid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "T07HNwdStdt3"
      },
      "outputs": [],
      "source": [
        "TRAIN_DATASET_PATH = 'Dataset/train_data.csv'\n",
        "TEST_DATASET_PATH = 'Dataset/test_data.csv'\n",
        "TARGET_COLUMN = 'Label'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Qqc-r-yp2UM"
      },
      "source": [
        "Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xpnwVaN3p0Ol"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(TRAIN_DATASET_PATH)\n",
        "df_test = pd.read_csv(TEST_DATASET_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxNvoc87p5Jt"
      },
      "source": [
        "Preprocessing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uJiSSn1Vp2DQ"
      },
      "outputs": [],
      "source": [
        "columns_to_drop = ['FlowID', 'SourceIP', 'DestinationIP', 'Timestamp']\n",
        "\n",
        "def preprocess_dataframe(df, columns_to_drop, target_column, desired_sample_size):\n",
        "    df_processed = df.drop(columns=columns_to_drop, errors='ignore').copy()\n",
        "\n",
        "    # Handle infinite and missing values\n",
        "    df_processed.replace([float('inf'), float('-inf')], pd.NA, inplace=True)\n",
        "    df_processed.fillna(0, inplace=True)\n",
        "\n",
        "    # Stratified downsampling (unless using full data)\n",
        "    if isinstance(desired_sample_size, str) and desired_sample_size.lower() == 'all':\n",
        "        df_sampled = df_processed\n",
        "    else:\n",
        "        sample_frac = desired_sample_size / len(df_processed)\n",
        "        df_sampled, _ = train_test_split(\n",
        "            df_processed,\n",
        "            test_size=1 - sample_frac,\n",
        "            stratify=df_processed[target_column],\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "    # Separate features (X) and target (y)\n",
        "    X = df_sampled.drop(columns=[target_column])\n",
        "    y = df_sampled[target_column]\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1djBLpKytod8"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = preprocess_dataframe(df_train, columns_to_drop, TARGET_COLUMN, 30000)\n",
        "X_test, y_test = preprocess_dataframe(df_test, columns_to_drop, TARGET_COLUMN, 'all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sI_AJ6YNuTxH"
      },
      "source": [
        "Encode labels (1 for BENIGN, 0 for ATTACK)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "q1PtxvEftqz9"
      },
      "outputs": [],
      "source": [
        "def simplify_labels(y):\n",
        "    return y.apply(lambda x: 'BENIGN' if x.upper() == 'BENIGN' else 'ATTACK')\n",
        "\n",
        "y_train = simplify_labels(y_train)\n",
        "y_test = simplify_labels(y_test)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "y_test = label_encoder.transform(y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ATTACK': 0, 'BENIGN': 1}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check mapping\n",
        "mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "mapping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFaKkpcd4nah"
      },
      "source": [
        "Scale features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "S8HQfCdK4nEO"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save the standard scaler\n",
        "#joblib.dump(scaler, 'scaler_semi_supervised.pkl')\n",
        "\n",
        "# save scaler using pickle\n",
        "with open('scaler_semi_supervised.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmDHq3NsvaHj"
      },
      "source": [
        "Unlabel data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7hBPs6Ysveyc"
      },
      "outputs": [],
      "source": [
        "# First convert y_train to a numpy array if it's not already\n",
        "y_train_array = y_train.values if hasattr(y_train, 'values') else np.array(y_train)\n",
        "\n",
        "# Create a copy of y_train with continuous indices\n",
        "indices = np.arange(len(y_train_array))\n",
        "\n",
        "# Keep 10% labeled randomly, stratified by class\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.9, random_state=42)\n",
        "labeled_idx, unlabeled_idx = next(sss.split(indices, y_train_array))\n",
        "\n",
        "# Create the semi-supervised target array\n",
        "y_train_semi = np.full(len(y_train_array), -1)\n",
        "y_train_semi[labeled_idx] = y_train_array[labeled_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FblxsqelzaTC"
      },
      "outputs": [],
      "source": [
        "def evaluate_semi_supervised_models(X_train_scaled, y_train, y_train_semi, n_splits=5, random_state=42):\n",
        "    # Ensure y_train is a NumPy array\n",
        "    y_train_array = y_train.values if hasattr(y_train, 'values') else np.array(y_train)\n",
        "\n",
        "    # Get labeled subset\n",
        "    labeled_indices = np.where(y_train_semi != -1)[0]\n",
        "    X_labeled = X_train_scaled[labeled_indices]\n",
        "    y_labeled = y_train_array[labeled_indices]\n",
        "\n",
        "    # Print class distribution\n",
        "    unique_classes, counts = np.unique(y_labeled, return_counts=True)\n",
        "    print(\"Class distribution in labeled data:\")\n",
        "    for cls, count in zip(unique_classes, counts):\n",
        "        print(f\"Class {cls}: {count} samples\")\n",
        "\n",
        "    # Define model factories\n",
        "    model_factories = {\n",
        "        'LabelSpreading': lambda: LabelSpreading(kernel='knn', n_neighbors=10, max_iter=200),\n",
        "        'LabelPropagation': lambda: LabelPropagation(kernel='knn', n_neighbors=10, max_iter=200),\n",
        "        'SelfTraining_LR': lambda: SelfTrainingClassifier(LogisticRegression(max_iter=1000, class_weight='balanced')),\n",
        "        'SelfTraining_RF': lambda: SelfTrainingClassifier(RandomForestClassifier(n_estimators=100, class_weight='balanced'))\n",
        "    }\n",
        "\n",
        "    results = {\n",
        "        'model': [], 'fold': [], 'accuracy': [], 'balanced_accuracy': [],\n",
        "        'weighted_f1': [], 'macro_f1': [],\n",
        "        'precision_weighted': [], 'precision_macro': [],\n",
        "        'recall_weighted': [], 'recall_macro': [],\n",
        "        'train_time': [], 'predict_time': []\n",
        "    }\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "\n",
        "    # Now outer loop over models\n",
        "    for model_name, model_factory in model_factories.items():\n",
        "        print(f\"\\n====================\")\n",
        "        print(f\"Evaluating {model_name}\")\n",
        "        print(\"====================\")\n",
        "\n",
        "        for fold, (train_idx, val_idx) in enumerate(skf.split(X_labeled, y_labeled)):\n",
        "            print(f\"  Fold {fold+1}/{n_splits}\")\n",
        "\n",
        "            # Validation fold\n",
        "            X_val_fold = X_labeled[val_idx]\n",
        "            y_val_fold = y_labeled[val_idx]\n",
        "\n",
        "            # Mask labels for semi-supervised training\n",
        "            y_train_semi_fold = np.full(len(y_train_array), -1)\n",
        "            labeled_train_indices = labeled_indices[train_idx]\n",
        "            y_train_semi_fold[labeled_train_indices] = y_train_array[labeled_train_indices]\n",
        "\n",
        "            # Set class weights for base estimator if supported\n",
        "            y_train_fold = y_train_array[labeled_train_indices]\n",
        "            classes = np.unique(y_train_fold)\n",
        "            class_weights = compute_class_weight('balanced', classes=classes, y=y_train_fold)\n",
        "            class_weight_dict = dict(zip(classes, class_weights))\n",
        "\n",
        "            model = model_factory()\n",
        "            if hasattr(model, \"base_estimator\") and hasattr(model.base_estimator, 'class_weight'):\n",
        "                model.base_estimator.class_weight = class_weight_dict\n",
        "\n",
        "            # Fit on full dataset using semi-supervised labels\n",
        "            train_start = time.time()\n",
        "            model.fit(X_train_scaled, y_train_semi_fold)\n",
        "            train_end = time.time()\n",
        "\n",
        "            # Predict on validation fold\n",
        "            predict_start = time.time()\n",
        "            y_val_pred = model.predict(X_val_fold)\n",
        "            predict_end = time.time()\n",
        "\n",
        "            # Evaluation metrics\n",
        "            acc = accuracy_score(y_val_fold, y_val_pred)\n",
        "            balanced_acc = balanced_accuracy_score(y_val_fold, y_val_pred)\n",
        "            f1_weighted = f1_score(y_val_fold, y_val_pred, average='weighted')\n",
        "            f1_macro = f1_score(y_val_fold, y_val_pred, average='macro')\n",
        "            precision_weighted = precision_score(y_val_fold, y_val_pred, average='weighted', zero_division=0)\n",
        "            precision_macro = precision_score(y_val_fold, y_val_pred, average='macro', zero_division=0)\n",
        "            recall_weighted = recall_score(y_val_fold, y_val_pred, average='weighted', zero_division=0)\n",
        "            recall_macro = recall_score(y_val_fold, y_val_pred, average='macro', zero_division=0)\n",
        "\n",
        "            # Store results\n",
        "            results['model'].append(model_name)\n",
        "            results['fold'].append(fold+1)\n",
        "            results['accuracy'].append(acc)\n",
        "            results['balanced_accuracy'].append(balanced_acc)\n",
        "            results['weighted_f1'].append(f1_weighted)\n",
        "            results['macro_f1'].append(f1_macro)\n",
        "            results['precision_weighted'].append(precision_weighted)\n",
        "            results['precision_macro'].append(precision_macro)\n",
        "            results['recall_weighted'].append(recall_weighted)\n",
        "            results['recall_macro'].append(recall_macro)\n",
        "            results['train_time'].append(train_end - train_start)\n",
        "            results['predict_time'].append(predict_end - predict_start)\n",
        "\n",
        "            print(f\"    Balanced Accuracy: {balanced_acc:.4f}, Macro F1: {f1_macro:.4f}, Macro Precision: {precision_macro:.4f}, Macro Recall: {recall_macro:.4f}\")\n",
        "\n",
        "    return pd.DataFrame(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKShTHkHdFMZ",
        "outputId": "9ad527b6-9ee9-4306-d005-bfd28c300959"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class distribution in labeled data:\n",
            "Class 0: 680 samples\n",
            "Class 1: 2320 samples\n",
            "\n",
            "====================\n",
            "Evaluating LabelSpreading\n",
            "====================\n",
            "  Fold 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jeffc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:230: RuntimeWarning: invalid value encountered in divide\n",
            "  probabilities /= normalizer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Balanced Accuracy: 0.9512, Macro F1: 0.9397, Macro Precision: 0.9295, Macro Recall: 0.9512\n",
            "  Fold 2/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jeffc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:230: RuntimeWarning: invalid value encountered in divide\n",
            "  probabilities /= normalizer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Balanced Accuracy: 0.9566, Macro F1: 0.9507, Macro Precision: 0.9452, Macro Recall: 0.9566\n",
            "  Fold 3/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jeffc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:230: RuntimeWarning: invalid value encountered in divide\n",
            "  probabilities /= normalizer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Balanced Accuracy: 0.9622, Macro F1: 0.9471, Macro Precision: 0.9341, Macro Recall: 0.9622\n",
            "  Fold 4/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jeffc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:230: RuntimeWarning: invalid value encountered in divide\n",
            "  probabilities /= normalizer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Balanced Accuracy: 0.9510, Macro F1: 0.9297, Macro Precision: 0.9126, Macro Recall: 0.9510\n",
            "  Fold 5/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jeffc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:230: RuntimeWarning: invalid value encountered in divide\n",
            "  probabilities /= normalizer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Balanced Accuracy: 0.9415, Macro F1: 0.9206, Macro Precision: 0.9039, Macro Recall: 0.9415\n",
            "\n",
            "====================\n",
            "Evaluating LabelPropagation\n",
            "====================\n",
            "  Fold 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jeffc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:322: ConvergenceWarning: max_iter=200 was reached without convergence.\n",
            "  warnings.warn(\n",
            "C:\\Users\\jeffc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:230: RuntimeWarning: invalid value encountered in divide\n",
            "  probabilities /= normalizer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Balanced Accuracy: 0.9527, Macro F1: 0.9379, Macro Precision: 0.9251, Macro Recall: 0.9527\n",
            "  Fold 2/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jeffc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:322: ConvergenceWarning: max_iter=200 was reached without convergence.\n",
            "  warnings.warn(\n",
            "C:\\Users\\jeffc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:230: RuntimeWarning: invalid value encountered in divide\n",
            "  probabilities /= normalizer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Balanced Accuracy: 0.9687, Macro F1: 0.9603, Macro Precision: 0.9526, Macro Recall: 0.9687\n",
            "  Fold 3/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jeffc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:322: ConvergenceWarning: max_iter=200 was reached without convergence.\n",
            "  warnings.warn(\n",
            "C:\\Users\\jeffc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:230: RuntimeWarning: invalid value encountered in divide\n",
            "  probabilities /= normalizer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Balanced Accuracy: 0.9653, Macro F1: 0.9433, Macro Precision: 0.9257, Macro Recall: 0.9653\n",
            "  Fold 4/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jeffc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:322: ConvergenceWarning: max_iter=200 was reached without convergence.\n",
            "  warnings.warn(\n",
            "C:\\Users\\jeffc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:230: RuntimeWarning: invalid value encountered in divide\n",
            "  probabilities /= normalizer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Balanced Accuracy: 0.9551, Macro F1: 0.9282, Macro Precision: 0.9080, Macro Recall: 0.9551\n",
            "  Fold 5/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jeffc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:322: ConvergenceWarning: max_iter=200 was reached without convergence.\n",
            "  warnings.warn(\n",
            "C:\\Users\\jeffc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:230: RuntimeWarning: invalid value encountered in divide\n",
            "  probabilities /= normalizer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Balanced Accuracy: 0.9436, Macro F1: 0.9248, Macro Precision: 0.9094, Macro Recall: 0.9436\n",
            "\n",
            "====================\n",
            "Evaluating SelfTraining_LR\n",
            "====================\n",
            "  Fold 1/5\n",
            "    Balanced Accuracy: 0.9353, Macro F1: 0.8956, Macro Precision: 0.8706, Macro Recall: 0.9353\n",
            "  Fold 2/5\n",
            "    Balanced Accuracy: 0.9192, Macro F1: 0.8964, Macro Precision: 0.8788, Macro Recall: 0.9192\n",
            "  Fold 3/5\n",
            "    Balanced Accuracy: 0.9318, Macro F1: 0.9022, Macro Precision: 0.8811, Macro Recall: 0.9318\n",
            "  Fold 4/5\n",
            "    Balanced Accuracy: 0.9271, Macro F1: 0.8769, Macro Precision: 0.8500, Macro Recall: 0.9271\n",
            "  Fold 5/5\n",
            "    Balanced Accuracy: 0.9282, Macro F1: 0.8788, Macro Precision: 0.8519, Macro Recall: 0.9282\n",
            "\n",
            "====================\n",
            "Evaluating SelfTraining_RF\n",
            "====================\n",
            "  Fold 1/5\n",
            "    Balanced Accuracy: 0.9989, Macro F1: 0.9976, Macro Precision: 0.9964, Macro Recall: 0.9989\n",
            "  Fold 2/5\n",
            "    Balanced Accuracy: 0.9926, Macro F1: 0.9952, Macro Precision: 0.9979, Macro Recall: 0.9926\n",
            "  Fold 3/5\n",
            "    Balanced Accuracy: 0.9952, Macro F1: 0.9952, Macro Precision: 0.9952, Macro Recall: 0.9952\n",
            "  Fold 4/5\n",
            "    Balanced Accuracy: 0.9890, Macro F1: 0.9928, Macro Precision: 0.9968, Macro Recall: 0.9890\n",
            "  Fold 5/5\n",
            "    Balanced Accuracy: 0.9831, Macro F1: 0.9857, Macro Precision: 0.9882, Macro Recall: 0.9831\n"
          ]
        }
      ],
      "source": [
        "results = evaluate_semi_supervised_models(X_train_scaled, y_train, y_train_semi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th colspan=\"2\" halign=\"left\">accuracy</th>\n",
              "      <th colspan=\"2\" halign=\"left\">balanced_accuracy</th>\n",
              "      <th colspan=\"2\" halign=\"left\">weighted_f1</th>\n",
              "      <th colspan=\"2\" halign=\"left\">macro_f1</th>\n",
              "      <th>train_time</th>\n",
              "      <th>...</th>\n",
              "      <th colspan=\"2\" halign=\"left\">predict_time</th>\n",
              "      <th colspan=\"2\" halign=\"left\">precision_weighted</th>\n",
              "      <th colspan=\"2\" halign=\"left\">precision_macro</th>\n",
              "      <th colspan=\"2\" halign=\"left\">recall_weighted</th>\n",
              "      <th colspan=\"2\" halign=\"left\">recall_macro</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>mean</th>\n",
              "      <th>...</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LabelPropagation</td>\n",
              "      <td>0.955333</td>\n",
              "      <td>0.010698</td>\n",
              "      <td>0.957087</td>\n",
              "      <td>0.010062</td>\n",
              "      <td>0.956221</td>\n",
              "      <td>0.010292</td>\n",
              "      <td>0.938903</td>\n",
              "      <td>0.014062</td>\n",
              "      <td>1.313264</td>\n",
              "      <td>...</td>\n",
              "      <td>0.030232</td>\n",
              "      <td>0.002781</td>\n",
              "      <td>0.959026</td>\n",
              "      <td>0.009053</td>\n",
              "      <td>0.924133</td>\n",
              "      <td>0.017974</td>\n",
              "      <td>0.955333</td>\n",
              "      <td>0.010698</td>\n",
              "      <td>0.957087</td>\n",
              "      <td>0.010062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LabelSpreading</td>\n",
              "      <td>0.954667</td>\n",
              "      <td>0.009603</td>\n",
              "      <td>0.952497</td>\n",
              "      <td>0.007685</td>\n",
              "      <td>0.955426</td>\n",
              "      <td>0.009174</td>\n",
              "      <td>0.937567</td>\n",
              "      <td>0.012428</td>\n",
              "      <td>0.948976</td>\n",
              "      <td>...</td>\n",
              "      <td>0.030493</td>\n",
              "      <td>0.009730</td>\n",
              "      <td>0.957544</td>\n",
              "      <td>0.007879</td>\n",
              "      <td>0.925063</td>\n",
              "      <td>0.016644</td>\n",
              "      <td>0.954667</td>\n",
              "      <td>0.009603</td>\n",
              "      <td>0.952497</td>\n",
              "      <td>0.007685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SelfTraining_LR</td>\n",
              "      <td>0.915667</td>\n",
              "      <td>0.010775</td>\n",
              "      <td>0.928322</td>\n",
              "      <td>0.006008</td>\n",
              "      <td>0.919021</td>\n",
              "      <td>0.009530</td>\n",
              "      <td>0.889984</td>\n",
              "      <td>0.011387</td>\n",
              "      <td>3.952677</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000440</td>\n",
              "      <td>0.000607</td>\n",
              "      <td>0.931104</td>\n",
              "      <td>0.004218</td>\n",
              "      <td>0.866483</td>\n",
              "      <td>0.014705</td>\n",
              "      <td>0.915667</td>\n",
              "      <td>0.010775</td>\n",
              "      <td>0.928322</td>\n",
              "      <td>0.006008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SelfTraining_RF</td>\n",
              "      <td>0.995333</td>\n",
              "      <td>0.003206</td>\n",
              "      <td>0.991785</td>\n",
              "      <td>0.006049</td>\n",
              "      <td>0.995323</td>\n",
              "      <td>0.003217</td>\n",
              "      <td>0.993314</td>\n",
              "      <td>0.004604</td>\n",
              "      <td>42.462959</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007232</td>\n",
              "      <td>0.000213</td>\n",
              "      <td>0.995341</td>\n",
              "      <td>0.003218</td>\n",
              "      <td>0.994897</td>\n",
              "      <td>0.003834</td>\n",
              "      <td>0.995333</td>\n",
              "      <td>0.003206</td>\n",
              "      <td>0.991785</td>\n",
              "      <td>0.006049</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows Ã— 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              model  accuracy           balanced_accuracy            \\\n",
              "                         mean       std              mean       std   \n",
              "0  LabelPropagation  0.955333  0.010698          0.957087  0.010062   \n",
              "1    LabelSpreading  0.954667  0.009603          0.952497  0.007685   \n",
              "2   SelfTraining_LR  0.915667  0.010775          0.928322  0.006008   \n",
              "3   SelfTraining_RF  0.995333  0.003206          0.991785  0.006049   \n",
              "\n",
              "  weighted_f1            macro_f1           train_time  ... predict_time  \\\n",
              "         mean       std      mean       std       mean  ...         mean   \n",
              "0    0.956221  0.010292  0.938903  0.014062   1.313264  ...     0.030232   \n",
              "1    0.955426  0.009174  0.937567  0.012428   0.948976  ...     0.030493   \n",
              "2    0.919021  0.009530  0.889984  0.011387   3.952677  ...     0.000440   \n",
              "3    0.995323  0.003217  0.993314  0.004604  42.462959  ...     0.007232   \n",
              "\n",
              "            precision_weighted           precision_macro            \\\n",
              "        std               mean       std            mean       std   \n",
              "0  0.002781           0.959026  0.009053        0.924133  0.017974   \n",
              "1  0.009730           0.957544  0.007879        0.925063  0.016644   \n",
              "2  0.000607           0.931104  0.004218        0.866483  0.014705   \n",
              "3  0.000213           0.995341  0.003218        0.994897  0.003834   \n",
              "\n",
              "  recall_weighted           recall_macro            \n",
              "             mean       std         mean       std  \n",
              "0        0.955333  0.010698     0.957087  0.010062  \n",
              "1        0.954667  0.009603     0.952497  0.007685  \n",
              "2        0.915667  0.010775     0.928322  0.006008  \n",
              "3        0.995333  0.003206     0.991785  0.006049  \n",
              "\n",
              "[4 rows x 21 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_agg = results.groupby('model').agg({\n",
        "    'accuracy': ['mean', 'std'],\n",
        "    'balanced_accuracy': ['mean', 'std'],\n",
        "    'weighted_f1': ['mean', 'std'],\n",
        "    'macro_f1': ['mean', 'std'],\n",
        "    'train_time': ['mean', 'std'],\n",
        "    'predict_time': ['mean', 'std'],\n",
        "    'precision_weighted': ['mean', 'std'],\n",
        "    'precision_macro': ['mean', 'std'],\n",
        "    'recall_weighted': ['mean', 'std'],\n",
        "    'recall_macro': ['mean', 'std']\n",
        "}).reset_index()\n",
        "results_agg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_best_semi_supervised_model(\n",
        "    results_df,\n",
        "    X_train_scaled,\n",
        "    y_train_semi,\n",
        "    metric='balanced_accuracy'\n",
        "):\n",
        "    \"\"\"\n",
        "    Selects and trains the best semi-supervised model based on cross-validation results.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    results_df : pd.DataFrame\n",
        "        Output from evaluate_semi_supervised_models.\n",
        "    X_train_scaled : np.ndarray\n",
        "        Scaled feature matrix for training.\n",
        "    y_train_semi : np.ndarray\n",
        "        Semi-supervised label array (-1 for unlabeled samples).\n",
        "    metric : str, default='balanced_accuracy'\n",
        "        Metric to use for selecting the best model.\n",
        "    save_path : str or None\n",
        "        Directory path to save the trained model as a pickle file (optional).\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    tuple: (best_model_name, trained_model, average_score, training_time)\n",
        "    \"\"\"\n",
        "    # Step 1: Validate metric\n",
        "    valid_metrics = ['accuracy', 'balanced_accuracy', 'weighted_f1', 'macro_f1']\n",
        "    if metric not in valid_metrics:\n",
        "        raise ValueError(f\"Metric must be one of {valid_metrics}\")\n",
        "\n",
        "    # Step 2: Aggregate performance across folds\n",
        "    results_agg = results_df.groupby('model').agg({metric: ['mean', 'std']}).reset_index()\n",
        "    results_agg.columns = ['model', f'{metric}_mean', f'{metric}_std']\n",
        "\n",
        "    # Step 3: Identify best model\n",
        "    best_row = results_agg.loc[results_agg[f'{metric}_mean'].idxmax()]\n",
        "    best_model_name = best_row['model']\n",
        "    best_model_score = best_row[f'{metric}_mean']\n",
        "    best_model_std = best_row[f'{metric}_std']\n",
        "\n",
        "    print(f\"\\nâœ… Best model based on {metric}: {best_model_name}\")\n",
        "    print(f\"   Avg {metric}: {best_model_score:.4f} Â± {best_model_std:.4f}\")\n",
        "\n",
        "    # Step 4: Instantiate best model\n",
        "    if best_model_name == 'LabelSpreading':\n",
        "        best_model = LabelSpreading(kernel='knn', n_neighbors=10, max_iter=200)\n",
        "    elif best_model_name == 'LabelPropagation':\n",
        "        best_model = LabelPropagation(kernel='knn', n_neighbors=10, max_iter=200)\n",
        "    elif best_model_name == 'SelfTraining_LR':\n",
        "        best_model = SelfTrainingClassifier(LogisticRegression(max_iter=1000, class_weight='balanced'))\n",
        "    elif best_model_name == 'SelfTraining_RF':\n",
        "        best_model = SelfTrainingClassifier(RandomForestClassifier(n_estimators=100, class_weight='balanced'))\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model name: {best_model_name}\")\n",
        "\n",
        "    # Step 5: Train on full dataset\n",
        "    print(f\"\\nðŸš€ Training {best_model_name} on full dataset ({len(X_train_scaled)} samples)...\")\n",
        "    start_time = time.time()\n",
        "    best_model.fit(X_train_scaled, y_train_semi)\n",
        "    training_time = time.time() - start_time\n",
        "    print(f\"   âœ… Training complete in {training_time:.2f} seconds\")\n",
        "\n",
        "    return best_model_name, best_model, best_model_score, training_time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.9335\n",
            "Test Weighted F1: 0.9354\n",
            "Test Weighted Recall: 0.9335\n",
            "Test Weighted Precision: 0.9419\n"
          ]
        }
      ],
      "source": [
        "ls_model = SelfTrainingClassifier(LogisticRegression(max_iter=1000, class_weight='balanced'))\n",
        "ls_model.fit(X_train_scaled, y_train_semi)\n",
        "y_test_pred = ls_model.predict(X_test_scaled)\n",
        "\n",
        "# get test performance\n",
        "test_acc = accuracy_score(y_test, y_test_pred)\n",
        "test_f1_weighted = f1_score(y_test, y_test_pred, average='weighted')\n",
        "test_recall_weighted = recall_score(y_test, y_test_pred, average='weighted')\n",
        "test_precision_weighted = precision_score(y_test, y_test_pred, average='weighted')\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "print(f\"Test Weighted F1: {test_f1_weighted:.4f}\")\n",
        "print(f\"Test Weighted Recall: {test_recall_weighted:.4f}\")\n",
        "print(f\"Test Weighted Precision: {test_precision_weighted:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âœ… Best model based on weighted_f1: SelfTraining_RF\n",
            "   Avg weighted_f1: 0.9953 Â± 0.0032\n",
            "\n",
            "ðŸš€ Training SelfTraining_RF on full dataset (30000 samples)...\n",
            "   âœ… Training complete in 49.07 seconds\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['SelfTraining_RF_semi_supervised.pkl']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the best model\n",
        "best_model_name, best_model, best_model_score, train_time = get_best_semi_supervised_model(results, X_train_scaled, y_train_semi, 'weighted_f1')\n",
        "\n",
        "# Save best model with name\n",
        "joblib.dump(best_model, f'{best_model_name}_semi_supervised.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_on_test_data(best_model, best_model_name, X_test_scaled, y_test_encoded, label_encoder=None):\n",
        "    \"\"\"\n",
        "    Evaluates a trained semi-supervised model on test data and prints metrics in a detailed format.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    best_model : sklearn estimator\n",
        "        Trained semi-supervised model (e.g., SelfTrainingClassifier).\n",
        "    X_test_scaled : np.ndarray\n",
        "        Scaled test features.\n",
        "    y_test_encoded : np.ndarray\n",
        "        Encoded true labels for the test set.\n",
        "    label_encoder : sklearn.preprocessing.LabelEncoder, optional\n",
        "        Used to decode class labels for readable classification report.\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    dict : Dictionary of evaluation results including accuracy, precision, recall, F1, classification report, and confusion matrix.\n",
        "    \"\"\"\n",
        "    print(f\"\\nEvaluating {best_model_name} on test data...\")\n",
        "    \n",
        "    start_time = time.time()\n",
        "    y_pred_encoded = best_model.predict(X_test_scaled)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Decode predictions for readable report (optional)\n",
        "    if label_encoder:\n",
        "        try:\n",
        "            target_names = label_encoder.classes_\n",
        "        except AttributeError:\n",
        "            target_names = None\n",
        "    else:\n",
        "        target_names = None\n",
        "\n",
        "    # Compute metrics\n",
        "    accuracy = accuracy_score(y_test_encoded, y_pred_encoded)\n",
        "    precision = precision_score(y_test_encoded, y_pred_encoded, average='weighted', zero_division=0)\n",
        "    recall = recall_score(y_test_encoded, y_pred_encoded, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_test_encoded, y_pred_encoded, average='weighted', zero_division=0)\n",
        "\n",
        "    # Generate classification report\n",
        "    try:\n",
        "        report = classification_report(y_test_encoded, y_pred_encoded, target_names=target_names, zero_division=0)\n",
        "        conf_matrix = confusion_matrix(y_test_encoded, y_pred_encoded)\n",
        "\n",
        "        print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
        "        print(f\"Precision (Weighted): {precision:.4f}\")\n",
        "        print(f\"Recall (Weighted): {recall:.4f}\")\n",
        "        print(f\"F1-Score (Weighted): {f1:.4f}\")\n",
        "        print(f\"Prediction Time (s): {prediction_time:.4f}\")\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(report)\n",
        "        print(\"\\nConfusion Matrix:\")\n",
        "        print(conf_matrix)\n",
        "    except ValueError as e:\n",
        "        print(\"Could not generate full classification report due to missing classes in test set.\")\n",
        "        report = \"Unavailable\"\n",
        "        conf_matrix = \"Unavailable\"\n",
        "        print(f\"Error details: {e}\")\n",
        "        print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
        "\n",
        "    return {\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision (Weighted)\": precision,\n",
        "        \"Recall (Weighted)\": recall,\n",
        "        \"F1-Score (Weighted)\": f1,\n",
        "        \"Classification Report\": report,\n",
        "        \"Confusion Matrix\": conf_matrix,\n",
        "        \"Prediction Time (s)\": prediction_time\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating SelfTraining_RF on test data...\n",
            "\n",
            "Accuracy: 0.9932\n",
            "Precision (Weighted): 0.9933\n",
            "Recall (Weighted): 0.9932\n",
            "F1-Score (Weighted): 0.9932\n",
            "Prediction Time (s): 4.2466\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      ATTACK       1.00      0.97      0.98    145426\n",
            "      BENIGN       0.99      1.00      1.00    494269\n",
            "\n",
            "    accuracy                           0.99    639695\n",
            "   macro avg       0.99      0.99      0.99    639695\n",
            "weighted avg       0.99      0.99      0.99    639695\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[141421   4005]\n",
            " [   316 493953]]\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the best model on test data\n",
        "test_results = evaluate_on_test_data(best_model, best_model_name, X_test_scaled, y_test, label_encoder)\n",
        "# Save test results to a file\n",
        "test_results_df = pd.DataFrame([test_results])\n",
        "test_results_df.to_csv(f'{best_model_name}_test_results.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "iCDVcsvX5473"
      },
      "outputs": [],
      "source": [
        "def optimize_self_training_rf(X_train_scaled, y_train_semi, cv=5):\n",
        "    \"\"\"\n",
        "    Optimize SelfTraining RandomForest using grid search with cross-validation.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    X_train_scaled : numpy.ndarray\n",
        "        Scaled training features\n",
        "    y_train_semi : numpy.ndarray\n",
        "        Semi-supervised labels for training (-1 for unlabeled samples)\n",
        "    cv : int, default=5\n",
        "        Number of cross-validation folds\n",
        "        \n",
        "    Returns:\n",
        "    --------\n",
        "    tuple: (best_model, best_params, cv_results)\n",
        "        Best model, best parameters, and cross-validation results\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    # Get labeled data indices for stratified CV\n",
        "    labeled_indices = np.where(y_train_semi != -1)[0]\n",
        "    y_labeled = y_train_semi[labeled_indices]\n",
        "    \n",
        "    # Create stratified k-fold for semi-supervised scenario\n",
        "    cv_splitter = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
        "    \n",
        "    # Define the parameter grid\n",
        "    param_grid = {\n",
        "        'base_estimator__n_estimators': [100, 200],\n",
        "        'base_estimator__max_depth': [None, 20],\n",
        "        'base_estimator__min_samples_split': [2, 5],\n",
        "        'base_estimator__min_samples_leaf': [1, 2],\n",
        "        'threshold': [0.7, 0.9]  # Self-training confidence threshold\n",
        "    }\n",
        "    \n",
        "    # Create base RF classifier\n",
        "    base_rf = RandomForestClassifier(\n",
        "        class_weight='balanced', \n",
        "        random_state=42\n",
        "    )\n",
        "    \n",
        "    # Create self-training classifier\n",
        "    self_training_model = SelfTrainingClassifier(\n",
        "        base_rf,\n",
        "        verbose=False\n",
        "    )\n",
        "    \n",
        "    # Define the grid search\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=self_training_model,\n",
        "        param_grid=param_grid,\n",
        "        scoring='f1_macro',\n",
        "        cv=cv_splitter.split(X_train_scaled[labeled_indices], y_labeled),\n",
        "        verbose=1,\n",
        "        n_jobs=-1  # Use all available cores\n",
        "    )\n",
        "    \n",
        "    print(\"Starting grid search for SelfTraining_RF...\")\n",
        "    print(\"This may take some time...\")\n",
        "    \n",
        "    # Prepare a mask for CV that only evaluates on labeled data\n",
        "    # but still allows the model to use unlabeled data for self-training\n",
        "    # Create train/test splits based on labeled data only, but fit on all data\n",
        "    \n",
        "    # Custom fit for semi-supervised grid search\n",
        "    best_score = -1\n",
        "    best_model = None\n",
        "    best_params = None\n",
        "    cv_results = []\n",
        "    \n",
        "    # Manual grid search approach tailored for semi-supervised learning\n",
        "    for params in ParameterGrid(param_grid):\n",
        "        fold_scores = []\n",
        "        \n",
        "        for train_idx, val_idx in cv_splitter.split(X_train_scaled[labeled_indices], y_labeled):\n",
        "            # Map indices back to original dataset indices\n",
        "            labeled_train_indices = labeled_indices[train_idx]\n",
        "            labeled_val_indices = labeled_indices[val_idx]\n",
        "            \n",
        "            # Create semi-supervised labels for this fold\n",
        "            y_fold = np.full_like(y_train_semi, -1)\n",
        "            y_fold[labeled_train_indices] = y_train_semi[labeled_train_indices]\n",
        "            \n",
        "            # Configure model with current parameters\n",
        "            base_est = RandomForestClassifier(\n",
        "                n_estimators=params['base_estimator__n_estimators'],\n",
        "                max_depth=params['base_estimator__max_depth'],\n",
        "                min_samples_split=params['base_estimator__min_samples_split'],\n",
        "                min_samples_leaf=params['base_estimator__min_samples_leaf'],\n",
        "                class_weight='balanced',\n",
        "                random_state=42\n",
        "            )\n",
        "            \n",
        "            model = SelfTrainingClassifier(\n",
        "                base_est,\n",
        "                threshold=params['threshold'],\n",
        "                verbose=False\n",
        "            )\n",
        "            \n",
        "            # Fit model on the fold's semi-supervised data\n",
        "            model.fit(X_train_scaled, y_fold)\n",
        "            \n",
        "            # Evaluate on the validation set (labeled data only)\n",
        "            y_val_pred = model.predict(X_train_scaled[labeled_val_indices])\n",
        "            score = balanced_accuracy_score(\n",
        "                y_train_semi[labeled_val_indices], \n",
        "                y_val_pred\n",
        "            )\n",
        "            \n",
        "            fold_scores.append(score)\n",
        "        \n",
        "        # Calculate average score across folds\n",
        "        mean_score = np.mean(fold_scores)\n",
        "        std_score = np.std(fold_scores)\n",
        "        \n",
        "        # Save result\n",
        "        cv_results.append({\n",
        "            'params': params,\n",
        "            'mean_score': mean_score,\n",
        "            'std_score': std_score\n",
        "        })\n",
        "        \n",
        "        print(f\"Params: {params}\")\n",
        "        print(f\"Score: {mean_score:.4f} Â± {std_score:.4f}\")\n",
        "        \n",
        "        # Update best if improved\n",
        "        if mean_score > best_score:\n",
        "            best_score = mean_score\n",
        "            best_params = params\n",
        "            \n",
        "    # Sort results by mean score\n",
        "    cv_results = sorted(cv_results, key=lambda x: x['mean_score'], reverse=True)\n",
        "    \n",
        "    # Create the best model with optimal parameters\n",
        "    best_base_est = RandomForestClassifier(\n",
        "        n_estimators=best_params['base_estimator__n_estimators'],\n",
        "        max_depth=best_params['base_estimator__max_depth'],\n",
        "        min_samples_split=best_params['base_estimator__min_samples_split'],\n",
        "        min_samples_leaf=best_params['base_estimator__min_samples_leaf'],\n",
        "        class_weight='balanced',\n",
        "        random_state=42\n",
        "    )\n",
        "    \n",
        "    best_model = SelfTrainingClassifier(\n",
        "        best_base_est,\n",
        "        threshold=best_params['threshold'],\n",
        "        verbose=False\n",
        "    )\n",
        "    \n",
        "    # Fit on the full training dataset\n",
        "    best_model.fit(X_train_scaled, y_train_semi)\n",
        "    \n",
        "    print(\"\\nBest parameters:\")\n",
        "    for param, value in best_params.items():\n",
        "        print(f\"{param}: {value}\")\n",
        "    \n",
        "    print(f\"\\nBest cross-validation score: {best_score:.4f}\")\n",
        "    \n",
        "    return best_model, best_params, cv_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['best_semi_supervised_model_optimized.pkl']"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get best model using optimization\n",
        "best_model_optimized, best_params_optimized, cv_results_optimized = optimize_self_training_rf(X_train_scaled, y_train_semi)\n",
        "# save best model optimized\n",
        "joblib.dump(best_model_optimized, 'best_semi_supervised_model_optimized.pkl')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
